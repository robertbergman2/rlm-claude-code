"""
Intelligent orchestrator using Claude for decision-making.

Implements: Spec §8.1 Phase 2 - Orchestration Layer

Uses Claude (Haiku for speed) to make orchestration decisions,
with fallback to heuristic-based complexity_classifier.
"""

from __future__ import annotations

import json
import re
import time
from dataclasses import dataclass
from typing import Any

from .api_client import ClaudeClient, init_client
from .complexity_classifier import should_activate_rlm
from .cost_tracker import CostComponent
from .orchestration_schema import (
    ExecutionMode,
    OrchestrationContext,
    OrchestrationPlan,
    ToolAccessLevel,
)
from .smart_router import ModelTier, QueryClassifier, QueryType
from .types import SessionContext

# System prompt for orchestration decisions
ORCHESTRATOR_SYSTEM_PROMPT = """You are an intelligent orchestration engine for RLM (Recursive Language Model) Claude Code.

Your role: Analyze queries to determine whether recursive decomposition adds value, and configure execution optimally.

## Core Philosophy: When Does RLM Add Value?

RLM excels when the problem benefits from **externalized reasoning** — breaking complex tasks into sub-queries that build understanding incrementally. The key question is: "Would thinking out loud in structured sub-steps lead to a better answer than direct response?"

### High-Value RLM Scenarios (activate_rlm: true)

**1. Discovery Required** — The answer requires exploring unknowns
- "Why is the API returning 500 errors?" → Need to trace call paths, check logs, examine state
- "How does authentication work in this codebase?" → Must follow data flow across files
- "What's causing this test to be flaky?" → Need to identify race conditions, timing issues

**2. Multi-Source Synthesis** — Answer requires integrating information from multiple places
- "Update all usages of the deprecated API" → Must find all call sites, understand each context
- "Ensure consistent error handling across services" → Cross-module pattern application
- "What's the impact of changing this schema?" → Trace all consumers

**3. Reasoning Under Uncertainty** — Multiple valid interpretations exist
- "Something feels wrong with this implementation" → Need to enumerate potential issues
- "Best approach for adding caching?" → Compare multiple strategies with tradeoffs
- Ambiguous requirements needing clarification through exploration

**4. Deep Debugging** — Error requires understanding multiple system layers
- Stack traces spanning multiple modules
- Intermittent failures (timing, state, environment-dependent)
- "This used to work" scenarios requiring diff analysis
- Errors where the symptom is far from the cause

**5. Architectural Reasoning** — Decisions with downstream implications
- "Should we use microservices or monolith?" → Need to evaluate constraints, tradeoffs
- Design decisions requiring constraint satisfaction across multiple dimensions
- Migration planning with dependency analysis

**6. Pattern Exhaustion** — Must ensure completeness
- "Find all security vulnerabilities" → Systematic enumeration required
- "Ensure all edge cases are handled" → Need structured coverage analysis
- Code review for a large changeset

**7. Context Recovery** — Previous attempts failed or were confused
- Prior response was incorrect or incomplete
- User says "that's not right" or "try again"
- Same question being asked differently (user unsatisfied)

### Low-Value RLM Scenarios (activate_rlm: false)

**Direct Knowledge** — Answer is immediately retrievable
- "What's the syntax for Python list comprehension?"
- "Show me the contents of config.yaml"
- Single file reads, simple command execution

**Narrow Scope** — Task is well-defined and localized
- "Add a type annotation to this function"
- "Fix the typo in the error message"
- Single-file, single-function changes with clear requirements

**User Explicitly Knows** — User provides complete context
- "Refactor this function using [specific approach]" with code provided
- Requests with complete specifications and no ambiguity
- Copy/transform operations with clear input and output

**Conversational** — Not a task, just interaction
- Acknowledgments, clarifications, follow-up questions
- "Thanks", "OK", "Yes, do that"

## Decision Dimensions

### execution_mode
- **fast**: User wants quick response, low-stakes task, or explicitly said "quick"/"just"
- **balanced**: Default — reasonable effort without excessive cost
- **thorough**: User said "make sure"/"careful"/"thorough", high-stakes, or previous attempt failed

### model_tier
- **fast**: Factual lookups, simple transformations, summarization
- **balanced**: Most coding tasks, standard analysis, debugging
- **powerful**: Architectural decisions, complex planning, nuanced judgment
- **code_specialist**: Heavy code generation, refactoring, debugging in unfamiliar codebases

### depth_budget (0-3)
Think of depth as "how many levels of sub-questions might we need?"
- **0**: Direct answer possible, no decomposition needed
- **1**: May need one round of information gathering
- **2**: Multi-step reasoning: explore → analyze → synthesize
- **3**: Deep investigation: explore → sub-explore → analyze → cross-reference → synthesize

### tool_access
- **none**: Pure reasoning from context already provided
- **repl_only**: Need computation but not file access
- **read_only**: Need to examine files/codebase but not modify
- **full**: Task requires file modifications or system changes

## Signals to Extract

Identify which of these apply (include all relevant ones in "signals"):
- multi_file_scope: Query spans multiple files or modules
- cross_module_reasoning: Need to understand interactions between components
- temporal_reasoning: Involves history, changes over time, "used to work"
- debugging_deep: Error requires tracing through layers
- debugging_surface: Error is localized and clear
- discovery_required: Need to find/explore unknown information
- synthesis_required: Must combine multiple sources
- uncertainty_high: Multiple valid interpretations
- user_frustrated: Prior attempts failed, user expressing dissatisfaction
- user_urgent: Speed signals ("quick", "just", "fast")
- user_careful: Quality signals ("make sure", "careful", "thorough", "verify")
- well_specified: User provided complete, unambiguous requirements
- architectural: Design decisions with tradeoffs
- pattern_exhaustion: Must ensure completeness/coverage
- continuation: Continuing previous work
- knowledge_retrieval: Answer is direct lookup
- narrow_scope: Localized, well-defined change

## Output Format

Output ONLY a JSON object (no markdown, no explanation):

{
  "activate_rlm": true/false,
  "activation_reason": "2-3 word primary reason",
  "execution_mode": "fast" | "balanced" | "thorough",
  "model_tier": "fast" | "balanced" | "powerful" | "code_specialist",
  "depth_budget": 0-3,
  "tool_access": "none" | "repl_only" | "read_only" | "full",
  "query_type": "code" | "debugging" | "analytical" | "planning" | "factual" | "search" | "summarization" | "refactoring" | "architecture" | "creative" | "unknown",
  "complexity_score": 0.0-1.0,
  "confidence": 0.0-1.0,
  "signals": ["signal1", "signal2", ...]
}

The confidence field (0.0-1.0) indicates how certain you are about this routing decision. Low confidence (<0.5) suggests the query is ambiguous and might benefit from RLM even if individual signals don't trigger it."""


@dataclass
class OrchestratorConfig:
    """Configuration for the intelligent orchestrator."""

    # Model to use for orchestration (haiku for speed)
    orchestrator_model: str = "haiku"

    # Timeout for orchestration call (ms)
    timeout_ms: int = 5000

    # Maximum tokens for orchestration response
    max_tokens: int = 500

    # Whether to use heuristic fallback on failure
    use_fallback: bool = True

    # Whether to cache recent decisions
    cache_enabled: bool = True
    cache_size: int = 100

    # === Local Model Options ===
    # Use local model instead of API for orchestration decisions
    use_local_model: bool = False

    # Local model configuration preset: "ultra_fast", "balanced", "quality", "portable"
    local_model_preset: str = "ultra_fast"

    # Whether to fallback to API if local model fails
    fallback_to_api: bool = True

    # === Logging Options ===
    # Enable decision logging for training data collection
    log_decisions: bool = False

    # Path for decision log file
    log_path: str = "~/.rlm/orchestration_decisions.jsonl"

    # Whether to log heuristic decisions (can be noisy)
    log_heuristics: bool = True


class IntelligentOrchestrator:
    """
    Uses Claude to make intelligent orchestration decisions.

    Implements: Spec §8.1 Phase 2 - Orchestration Layer

    Supports three orchestration modes:
    1. Local model (fastest, no API cost) - use_local_model=True
    2. API-based (Claude Haiku) - default
    3. Heuristic fallback - when both fail

    Falls back to heuristic classifier on LLM failure.
    """

    def __init__(
        self,
        client: ClaudeClient | None = None,
        config: OrchestratorConfig | None = None,
        available_models: list[str] | None = None,
    ):
        """
        Initialize the intelligent orchestrator.

        Args:
            client: Claude API client (creates one if None)
            config: Orchestrator configuration
            available_models: List of available model names
        """
        self._client = client
        self.config = config or OrchestratorConfig()
        self.available_models = available_models or ["sonnet", "haiku", "opus"]
        self._query_classifier = QueryClassifier()
        self._decision_cache: dict[str, OrchestrationPlan] = {}
        self._local_orchestrator: Any = None  # Lazy initialized
        self._decision_logger: Any = None  # Lazy initialized
        self._stats = {
            "llm_decisions": 0,
            "local_decisions": 0,
            "fallback_decisions": 0,
            "cache_hits": 0,
            "errors": 0,
        }

    def _ensure_logger(self) -> Any:
        """Lazily initialize decision logger."""
        if self._decision_logger is None and self.config.log_decisions:
            from .orchestration_logger import LoggerConfig, OrchestrationLogger

            log_config = LoggerConfig(
                log_path=self.config.log_path,
                enabled=True,
                log_heuristics=self.config.log_heuristics,
            )
            self._decision_logger = OrchestrationLogger(config=log_config)
        return self._decision_logger

    def _ensure_local_orchestrator(self) -> Any:
        """Lazily initialize local orchestrator."""
        if self._local_orchestrator is None:
            from .local_orchestrator import RECOMMENDED_CONFIGS, LocalOrchestrator

            preset = self.config.local_model_preset
            if preset in RECOMMENDED_CONFIGS:
                local_config = RECOMMENDED_CONFIGS[preset]
            else:
                from .local_orchestrator import LocalModelConfig
                local_config = LocalModelConfig()

            self._local_orchestrator = LocalOrchestrator(
                config=local_config,
                system_prompt=ORCHESTRATOR_SYSTEM_PROMPT,
            )
        return self._local_orchestrator

    def _ensure_client(self) -> ClaudeClient:
        """Ensure we have an API client."""
        if self._client is None:
            self._client = init_client()
        return self._client

    async def create_plan(
        self,
        query: str,
        context: OrchestrationContext | SessionContext,
    ) -> OrchestrationPlan:
        """
        Create an orchestration plan for a query.

        Uses Claude for intelligent decision-making,
        falls back to heuristics on failure.

        Args:
            query: The user query
            context: Orchestration context or session context

        Returns:
            OrchestrationPlan with the decision
        """
        # Convert SessionContext to OrchestrationContext if needed
        if isinstance(context, SessionContext):
            orch_context = OrchestrationContext(
                query=query,
                context_tokens=context.total_tokens,
                available_models=self.available_models,
            )
        else:
            orch_context = context

        # Check forced overrides
        if orch_context.forced_rlm is False:
            return OrchestrationPlan.bypass("user_forced_off")

        if orch_context.forced_mode is not None:
            return OrchestrationPlan.from_mode(
                orch_context.forced_mode,
                activation_reason="user_forced_mode",
                available_models=self.available_models,
            )

        # Check cache
        cache_key = self._compute_cache_key(query, orch_context)
        if self.config.cache_enabled and cache_key in self._decision_cache:
            self._stats["cache_hits"] += 1
            return self._decision_cache[cache_key]

        # Build context summary for logging
        context_summary = self._summarize_context(orch_context)

        # Try local model first if configured
        if self.config.use_local_model:
            try:
                start_time = time.time()
                plan = await self._local_orchestrate(query, orch_context)
                latency_ms = (time.time() - start_time) * 1000
                self._stats["local_decisions"] += 1

                # Log decision
                self._log_decision(query, context_summary, plan, "local", latency_ms, orch_context)

                # Cache the decision
                if self.config.cache_enabled:
                    self._update_cache(cache_key, plan)

                return plan

            except Exception as e:
                self._stats["errors"] += 1
                # Fall through to API if configured
                if not self.config.fallback_to_api:
                    if self.config.use_fallback:
                        self._stats["fallback_decisions"] += 1
                        plan = self._heuristic_orchestrate(query, orch_context)
                        self._log_decision(query, context_summary, plan, "heuristic", 0, orch_context)
                        return plan
                    raise RuntimeError(f"Local orchestration failed: {e}") from e

        # Try API-based orchestration
        try:
            start_time = time.time()
            plan = await self._llm_orchestrate(query, orch_context)
            latency_ms = (time.time() - start_time) * 1000
            self._stats["llm_decisions"] += 1

            # Log decision
            self._log_decision(query, context_summary, plan, "api", latency_ms, orch_context)

            # Cache the decision
            if self.config.cache_enabled:
                self._update_cache(cache_key, plan)

            return plan

        except Exception as e:
            self._stats["errors"] += 1

            # Fallback to heuristics
            if self.config.use_fallback:
                self._stats["fallback_decisions"] += 1
                plan = self._heuristic_orchestrate(query, orch_context)
                self._log_decision(query, context_summary, plan, "heuristic", 0, orch_context)
                return plan
            else:
                raise RuntimeError(f"Orchestration failed: {e}") from e

    def _log_decision(
        self,
        query: str,
        context_summary: str,
        plan: OrchestrationPlan,
        source: str,
        latency_ms: float,
        context: OrchestrationContext,
    ) -> None:
        """Log an orchestration decision for training data."""
        logger = self._ensure_logger()
        if logger is None:
            return

        decision = plan.to_dict()
        logger.log_decision(
            query=query,
            context_summary=context_summary,
            decision=decision,
            source=source,
            latency_ms=latency_ms,
            context_tokens=context.context_tokens,
            model_used=self.config.orchestrator_model if source == "api" else "",
        )

    async def _llm_orchestrate(
        self,
        query: str,
        context: OrchestrationContext,
    ) -> OrchestrationPlan:
        """Use Claude to make orchestration decision."""
        client = self._ensure_client()

        # Build context summary for orchestrator
        context_summary = self._summarize_context(context)

        user_message = f"""Analyze this query and decide how to process it:

Query: {query}

Context:
{context_summary}

Output your decision as a JSON object."""

        # Call the orchestrator model
        response = await client.complete(
            messages=[{"role": "user", "content": user_message}],
            system=ORCHESTRATOR_SYSTEM_PROMPT,
            model=self.config.orchestrator_model,
            max_tokens=self.config.max_tokens,
            component=CostComponent.ROOT_PROMPT,
        )

        # Parse the response
        return self._parse_decision(response.content, query, context)

    async def _local_orchestrate(
        self,
        query: str,
        context: OrchestrationContext,
    ) -> OrchestrationPlan:
        """Use local model to make orchestration decision."""
        local_orch = self._ensure_local_orchestrator()

        # Build context summary for orchestrator
        context_summary = self._summarize_context(context)

        # Get decision from local model
        decision = await local_orch.orchestrate(
            query=query,
            context_summary=context_summary,
        )

        # Convert decision dict to OrchestrationPlan
        return self._parse_decision(json.dumps(decision), query, context)

    def _summarize_context(self, context: OrchestrationContext) -> str:
        """Summarize context for orchestrator with rich signals."""
        lines = [
            f"- Context tokens: {context.context_tokens:,}",
            f"- Current recursion depth: {context.current_depth}/3",
            f"- Remaining budget: ${context.budget_remaining_dollars:.2f}",
            f"- Remaining tokens: {context.budget_remaining_tokens:,}",
        ]

        if context.tokens_used > 0:
            lines.append(f"- Tokens used so far: {context.tokens_used:,}")

        # Add context size interpretation
        if context.context_tokens > 100_000:
            lines.append("- [SIGNAL] Very large context - may benefit from RLM decomposition")
        elif context.context_tokens > 50_000:
            lines.append("- [SIGNAL] Large context - moderate complexity likely")

        # Add depth interpretation
        if context.current_depth > 0:
            lines.append(f"- [SIGNAL] Already in recursive call (depth {context.current_depth})")

        if context.complexity_signals:
            signals = [k for k, v in context.complexity_signals.items() if v]
            if signals:
                lines.append(f"- Detected complexity signals: {', '.join(signals)}")

        if context.forced_model:
            lines.append(f"- User requested model: {context.forced_model}")

        if context.forced_mode:
            lines.append(f"- User requested mode: {context.forced_mode.value}")

        return "\n".join(lines)

    def _parse_decision(
        self,
        response: str,
        query: str,
        context: OrchestrationContext,
    ) -> OrchestrationPlan:
        """Parse LLM response into OrchestrationPlan."""
        # Extract JSON from response
        json_match = re.search(r"\{[^{}]*\}", response, re.DOTALL)
        if not json_match:
            raise ValueError(f"No JSON found in response: {response[:200]}")

        try:
            data = json.loads(json_match.group())
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON in response: {e}") from e

        # Parse enums
        execution_mode = ExecutionMode(data.get("execution_mode", "balanced"))
        tool_access = ToolAccessLevel(data.get("tool_access", "read_only"))

        # Map model_tier string to enum
        tier_mapping = {
            "fast": ModelTier.FAST,
            "balanced": ModelTier.BALANCED,
            "powerful": ModelTier.POWERFUL,
            "code_specialist": ModelTier.CODE_SPECIALIST,
        }
        model_tier = tier_mapping.get(
            data.get("model_tier", "balanced"),
            ModelTier.BALANCED,
        )

        # Map query_type string to enum
        query_type_mapping = {
            "code": QueryType.CODE,
            "debugging": QueryType.DEBUGGING,
            "analytical": QueryType.ANALYTICAL,
            "planning": QueryType.PLANNING,
            "factual": QueryType.FACTUAL,
            "search": QueryType.SEARCH,
            "summarization": QueryType.SUMMARIZATION,
            "refactoring": QueryType.REFACTORING,
            "architecture": QueryType.ARCHITECTURE,
            "creative": QueryType.CREATIVE,
            "unknown": QueryType.UNKNOWN,
        }
        query_type = query_type_mapping.get(
            data.get("query_type", "unknown"),
            QueryType.UNKNOWN,
        )

        # Select model based on tier and availability
        primary_model = self._select_model(model_tier)

        # Extract confidence - low confidence may trigger RLM even if not explicitly activated
        confidence = data.get("confidence", 0.7)
        activate_rlm = data.get("activate_rlm", True)

        # If confidence is low (<0.5) and RLM was not activated, consider activating anyway
        # This captures edge cases where the orchestrator is uncertain
        if not activate_rlm and confidence < 0.5:
            activate_rlm = True
            activation_reason = "low_confidence_safety"
        else:
            activation_reason = data.get("activation_reason", "llm_decision")

        return OrchestrationPlan(
            activate_rlm=activate_rlm,
            activation_reason=activation_reason,
            model_tier=model_tier,
            primary_model=primary_model,
            fallback_chain=self._get_fallbacks(model_tier, primary_model),
            depth_budget=min(3, max(0, data.get("depth_budget", 2))),
            tokens_per_depth=25_000,
            execution_mode=execution_mode,
            tool_access=tool_access,
            query_type=query_type,
            complexity_score=data.get("complexity_score", 0.5),
            confidence=confidence,
            signals=data.get("signals", []),
        )

    def _select_model(self, tier: ModelTier) -> str:
        """Select best available model for tier."""
        from .orchestration_schema import TIER_MODELS

        tier_models = TIER_MODELS.get(tier, TIER_MODELS[ModelTier.BALANCED])
        for model in tier_models:
            if model in self.available_models:
                return model

        # Fallback
        return self.available_models[0] if self.available_models else "sonnet"

    def _get_fallbacks(self, tier: ModelTier, primary: str) -> list[str]:
        """Get fallback models for the tier."""
        from .orchestration_schema import TIER_MODELS

        tier_models = TIER_MODELS.get(tier, TIER_MODELS[ModelTier.BALANCED])
        fallbacks = [m for m in tier_models if m in self.available_models and m != primary]
        return fallbacks[:2]  # Up to 2 fallbacks

    def _heuristic_orchestrate(
        self,
        query: str,
        context: OrchestrationContext,
    ) -> OrchestrationPlan:
        """
        Enhanced heuristic-based orchestration aligned with the new philosophy.

        This fallback captures the key signals from the improved prompt without
        requiring an LLM call. It's designed to be conservative (bias toward RLM
        activation when uncertain) while avoiding unnecessary overhead for
        clearly simple tasks.
        """
        query_lower = query.lower()

        # === High-Value RLM Signals (activate if any are present) ===
        high_value_signals: list[str] = []

        # 1. Discovery Required
        discovery_patterns = [
            r"\bwhy\s+(is|does|did|are|was|were)\b",
            r"\bhow\s+does\b.*\bwork\b",
            r"\bwhat('s| is)\s+causing\b",
            r"\bwhere\s+(is|are|does)\b.*\b(defined|implemented|used|called)\b",
            r"\btrace\b",
            r"\bfollow\b.*\b(flow|path|data)\b",
        ]
        if any(re.search(p, query_lower) for p in discovery_patterns):
            high_value_signals.append("discovery_required")

        # 2. Multi-Source Synthesis
        synthesis_patterns = [
            r"\ball\s+(usages?|instances?|occurrences?|references?)\b",
            r"\bupdate\s+(all|every)\b",
            r"\bensure\s+(consistent|all)\b",
            r"\bimpact\s+of\s+(changing|modifying)\b",
            r"\bacross\s+(modules?|files?|services?|components?)\b",
        ]
        if any(re.search(p, query_lower) for p in synthesis_patterns):
            high_value_signals.append("synthesis_required")

        # 3. Uncertainty / Multiple Interpretations
        uncertainty_patterns = [
            r"\b(best|better|optimal|right)\s+(way|approach|method)\b",
            r"\bshould\s+(i|we)\b",
            r"\bcompare\b.*\b(options?|approaches?|strategies?)\b",
            r"\btrade.?offs?\b",
            r"\bpros?\s+and\s+cons?\b",
            r"\bsomething\s+(feels?|seems?)\s+(wrong|off|weird)\b",
        ]
        if any(re.search(p, query_lower) for p in uncertainty_patterns):
            high_value_signals.append("uncertainty_high")

        # 4. Deep Debugging
        deep_debug_patterns = [
            r"\bintermittent\b",
            r"\bflaky\b",
            r"\brandom(ly)?\s+(fails?|errors?)\b",
            r"\brace\s+condition\b",
            r"\bused\s+to\s+work\b",
            r"\bstack\s*trace\b",
            r"\bmultiple\s+(errors?|failures?|exceptions?)\b",
            r"\bcan'?t\s+(figure|understand)\b",
        ]
        if any(re.search(p, query_lower) for p in deep_debug_patterns):
            high_value_signals.append("debugging_deep")

        # 5. Architectural Reasoning
        architecture_patterns = [
            r"\b(design|architect)\b.*\b(system|api|service)\b",
            r"\bmicroservices?\b",
            r"\bmonolith\b",
            r"\bscalability\b",
            r"\bmigrat(e|ion)\b",
            r"\brefactor\b.*\b(entire|whole|major)\b",
        ]
        if any(re.search(p, query_lower) for p in architecture_patterns):
            high_value_signals.append("architectural")

        # 6. Pattern Exhaustion / Completeness
        exhaustion_patterns = [
            r"\bfind\s+all\b",
            r"\b(every|all)\s+(edge\s+)?cases?\b",
            r"\bcomprehensive\b",
            r"\bsecurity\s+(audit|review|vulnerabilities?)\b",
            r"\bmake\s+sure\b.*\b(all|every|nothing)\b",
            r"\bmissing\s+(anything|something)\b",
        ]
        if any(re.search(p, query_lower) for p in exhaustion_patterns):
            high_value_signals.append("pattern_exhaustion")

        # 7. Context Recovery (from context signals)
        if context.complexity_signals.get("previous_turn_was_confused"):
            high_value_signals.append("user_frustrated")

        # === Low-Value Signals (skip RLM if ONLY these are present) ===
        low_value_signals: list[str] = []

        # Direct Knowledge
        knowledge_patterns = [
            r"^(show|cat|read|view|open)\s+[\w./]+$",
            r"^what('s| is)\s+the\s+syntax\b",
            r"^how\s+do\s+(i|you)\s+(write|use)\b.*\bin\s+\w+$",
        ]
        if any(re.match(p, query_lower) for p in knowledge_patterns):
            low_value_signals.append("knowledge_retrieval")

        # Narrow Scope
        narrow_patterns = [
            r"^(add|fix|change|update)\s+(a|the|this)\s+(typo|comment|annotation|import)\b",
            r"^rename\s+\w+\s+to\s+\w+$",
        ]
        if any(re.match(p, query_lower) for p in narrow_patterns):
            low_value_signals.append("narrow_scope")

        # Conversational
        conversational_patterns = [
            r"^(ok(ay)?|yes|no|sure|thanks?|got\s+it|understood)\.?$",
            r"^(do\s+(it|that)|go\s+ahead|proceed|continue)\.?$",
        ]
        if any(re.match(p, query_lower.strip()) for p in conversational_patterns):
            low_value_signals.append("conversational")
            return OrchestrationPlan.bypass("conversational")

        # === User Intent Signals ===
        user_signals: list[str] = []

        # Urgency
        if re.search(r"\b(quick(ly)?|just|fast|simple)\b", query_lower):
            user_signals.append("user_urgent")

        # Carefulness
        if re.search(r"\b(make\s+sure|careful(ly)?|thorough(ly)?|verify|double.?check)\b", query_lower):
            user_signals.append("user_careful")

        # === Decision Logic ===
        all_signals = high_value_signals + low_value_signals + user_signals

        # If only low-value signals and no high-value signals, skip RLM
        if low_value_signals and not high_value_signals:
            # Unless it's a large context
            if context.context_tokens < 50_000:
                return OrchestrationPlan.bypass(f"low_value:{low_value_signals[0]}")

        # Get query classification for type
        classification = self._query_classifier.classify(query)

        # Determine if RLM should activate
        should_activate = len(high_value_signals) > 0 or context.context_tokens > 80_000

        # Also check traditional signals
        session_context = SessionContext(
            messages=[],
            files={},
            tool_outputs=[],
            working_memory={},
        )
        traditional_activate, traditional_reason = should_activate_rlm(query, session_context)

        if traditional_activate and not should_activate:
            should_activate = True
            all_signals.append(traditional_reason)

        if not should_activate:
            return OrchestrationPlan.bypass("simple_task")

        # Determine execution mode
        if "user_careful" in user_signals or "pattern_exhaustion" in high_value_signals:
            mode = ExecutionMode.THOROUGH
        elif "user_urgent" in user_signals and len(high_value_signals) <= 1:
            mode = ExecutionMode.FAST
        elif classification.complexity > 0.7 or len(high_value_signals) >= 2:
            mode = ExecutionMode.THOROUGH
        elif classification.complexity < 0.3 and len(high_value_signals) <= 1:
            mode = ExecutionMode.FAST
        else:
            mode = ExecutionMode.BALANCED

        # Determine depth budget based on signals
        if "debugging_deep" in high_value_signals or "architectural" in high_value_signals:
            depth_budget = 3
        elif "synthesis_required" in high_value_signals or "pattern_exhaustion" in high_value_signals or "discovery_required" in high_value_signals:
            depth_budget = 2
        else:
            depth_budget = 1

        # Determine primary reason
        if high_value_signals:
            activation_reason = high_value_signals[0]
        else:
            activation_reason = "complexity_threshold"

        # Build plan from mode
        plan = OrchestrationPlan.from_mode(
            mode,
            query_type=classification.query_type,
            activation_reason=activation_reason,
            available_models=self.available_models,
        )

        # Override depth if we computed a specific one
        plan.depth_budget = min(depth_budget, plan.depth_budget + 1)

        # Add all signals
        plan.complexity_score = classification.complexity
        plan.signals = all_signals
        plan.confidence = classification.confidence

        return plan

    def _compute_cache_key(self, query: str, context: OrchestrationContext) -> str:
        """Compute cache key for a query."""
        # Simple cache key based on query prefix and context state
        query_prefix = query[:100].lower().strip()
        context_key = f"{context.context_tokens // 10000}_{context.current_depth}"
        return f"{hash(query_prefix)}_{context_key}"

    def _update_cache(self, key: str, plan: OrchestrationPlan) -> None:
        """Update cache with new decision."""
        if len(self._decision_cache) >= self.config.cache_size:
            # Remove oldest entries
            oldest = list(self._decision_cache.keys())[: self.config.cache_size // 4]
            for k in oldest:
                del self._decision_cache[k]

        self._decision_cache[key] = plan

    def get_statistics(self) -> dict[str, Any]:
        """Get orchestration statistics."""
        total = (
            self._stats["llm_decisions"]
            + self._stats["local_decisions"]
            + self._stats["fallback_decisions"]
            + self._stats["cache_hits"]
        )
        return {
            **self._stats,
            "total_decisions": total,
            "llm_rate": self._stats["llm_decisions"] / total if total > 0 else 0.0,
            "local_rate": self._stats["local_decisions"] / total if total > 0 else 0.0,
            "cache_hit_rate": self._stats["cache_hits"] / total if total > 0 else 0.0,
            "error_rate": self._stats["errors"] / (total + self._stats["errors"]) if total > 0 else 0.0,
        }


# Convenience function for one-shot orchestration
async def create_orchestration_plan(
    query: str,
    context: SessionContext | OrchestrationContext,
    client: ClaudeClient | None = None,
    use_llm: bool = True,
) -> OrchestrationPlan:
    """
    Create an orchestration plan for a query.

    Args:
        query: User query
        context: Session or orchestration context
        client: Optional Claude client
        use_llm: Whether to use LLM-based orchestration

    Returns:
        OrchestrationPlan
    """
    config = OrchestratorConfig(use_fallback=True)

    if not use_llm:
        # Use heuristics only
        orchestrator = IntelligentOrchestrator(config=config)
        if isinstance(context, SessionContext):
            orch_context = OrchestrationContext(
                query=query,
                context_tokens=context.total_tokens,
            )
        else:
            orch_context = context
        return orchestrator._heuristic_orchestrate(query, orch_context)

    orchestrator = IntelligentOrchestrator(client=client, config=config)
    return await orchestrator.create_plan(query, context)


__all__ = [
    "IntelligentOrchestrator",
    "OrchestratorConfig",
    "create_orchestration_plan",
]
